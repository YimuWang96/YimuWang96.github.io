<html>
   <head></head>
   <body>
      <link rel="stylesheet" type="text/css" href="./github.css" id="_theme">
      <div id="_html" class="markdown-body">
         <meta charset="UTF-8">
         <title>DA-Retail Dataset Project Page</title>
         <meta name="description" content="A Large-Scale Retail Product Checkout Dataset">
         <meta name="keywords" content="rpc dataset, rpctool, retail, product detection">
         <link rel="shortcut icon" href="./favicon.ico">
         <div align="center">
            <h1 id="an-adversarial-domain-adaptation-network-for-cross-domain-fine-grained-recognition">An Adversarial Domain Adaptation Network for Cross-Domain Fine-Grained Recognition</h1>
            <p><strong><a href="https://yimuwang96.github.io/">Yimu Wang<sup>1</sup></a> &nbsp;&nbsp;&nbsp;Ren-Jie Song<sup>2</sup> &nbsp;&nbsp;&nbsp;<a href="http://www.weixiushen.com/">Xiu-Shen Wei<sup>2</sup></a> &nbsp;&nbsp;&nbsp;<a href="https://cs.nju.edu.cn/zlj/">Lijun Zhang<sup>1</sup></a> &nbsp;&nbsp;&nbsp;</strong></p>
            <p><sup>1</sup>Department of Computer Science and Technology, Nanjing University, Nanjing, China<br><sup>2</sup>Megvii Research Nanjing, Megvii Technology Ltd., Nanjing, China    </p>
            <hr>
            <h3 id="abstract--paper--dataset--proposed-method--cite"><a href="#1-abstract">Abstract</a> | <a href="#2-paper">Paper</a> | <a href="#3-DA-Retail">Dataset</a> | <a href="#4-proposed-method-on-the-da-retail-dataset">Proposed Method</a> | <a href="#5-cite">Cite</a></h3>
         </div>
         <h2 id="1-abstract"><a class="anchor" name="1-abstract" href="#1-abstract"><span class="octicon octicon-link"></span></a>1. Abstract</h2>
         <p style="text-align: justify"><em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In this paper, we tackle a valuable yet very challenging visual recognition task, where the instances are within a sub- ordinate category, and the target domain undergoes a shift with the source domain. This task, termed as cross-domain fine-grained recognition, relates closely to many real-life sce- narios, e.g., recognizing retail products in storage racks by models trained with images collected in controlled environ- ments. To deal with this problem, we design a new algorithm and propose a corresponding fine-grained domain adapta- tion dataset. Firstly, we propose a novel end-to-end CNN architecture that integrates two specialized modules: an ad- versarial module for domain alignment and a self-attention module for fine-grained recognition. The adversarial module is used to handle domain shift by gradually aligning the dif- ferent domains with domain-level and class-level alignments, and strive to help the classifier learn with domain-invariant features generated by nets. The self-attention module is de- signed to capture discriminative image regions which are crucial for fine-grained visual recognition. Secondly, we col- lect a large-scale fine-grained domain adaptation dataset of retail products, which contains 52,011 images of 263 classes from 3 domains. Thirdly, we validate the effectiveness of our method on three datasets, showing that the proposed method can yield significant improvements over baseline methods on fine-grained datasets. Besides, we also evaluate the effectiveness of the self-attention module by performing visualization, which can capture the discriminative image regions in both source and target domains.
            </em>
         </p>
         <h2 id="2-paper"><a class="anchor" name="2-paper" href="#2-paper"><span class="octicon octicon-link"></span></a>2. Paper</h2>
         <div align="center">
            <p><a href="NULL"><strong>Paper will be released after the conference!</strong></a></p>
         </div>
         <h2 id="3-our-da-retail-dataset"><a class="anchor" name="3-our-da-retail-dataset" href="#3-our-da-retail-dataset"><span class="octicon octicon-link"></span></a>3. Our DA-Retail dataset</h2>
         <div align="left">
            <p>DA-Retail consists of 52,011 images of 263 fine-grained classes from 3 domains. Abundant images from multiple sources make our dataset more challenging. The collected fine-grained products are from the retail scenario, e.g., istant noodles, fruit juice, mineral water, yogurt, and milk.</p>
         </div>
         <div align="center">
            <p><a href="NULL"><strong>Dataset will be released after the conference!</strong></a></p>
            <div align="center">
               <img style="width:700px" src="imgs/dataset.png">
            </div>
         </div>
         <p>Dataset license:<br><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png" alt=""></a><br>CC BY-NC-SA 4.0</p>
         <h2 id="4-proposed-method-on-the-da-retail-dataset"><a class="anchor" name="4-proposed-method-on-the-da-retail-dataset" href="#4-proposed-method-on-the-da-retail-dataset"><span class="octicon octicon-link"></span></a>4. Proposed method on the DA-Retail dataset</h2>
         <h4 id="41-pipeline-of-our-method"><a class="anchor" name="41-pipeline-of-our-method" href="#41-pipeline-of-our-method"><span class="octicon octicon-link"></span></a>4.1 Pipeline of our method</h4>
         <div align="center">
            <img style="width:700px" src="imgs/model.png">
         </div>
         <h4 id="42-experimental-results"><a class="anchor" name="42-experimental-results" href="#42-experimental-results"><span class="octicon octicon-link"></span></a>4.2 Experimental results</h4>
         <div align="center">
            <img style="width:700px" src="imgs/results.png">
         </div>
         <h4 id="43-source-codes"><a class="anchor" name="43-source-codes" href="#43-source-codes"><span class="octicon octicon-link"></span></a>4.3 Source Codes</h4>
         <div align="center">
            <p><a href="NULL"><strong>Source codes will be released after the conference!</strong></a></p>
         </div>
         <h2 id="5-cite"><a class="anchor" name="5-cite" href="#5-cite"><span class="octicon octicon-link"></span></a>5. Cite</h2>
         <div align="left">
            <pre><code>@inproceedings{wang20,
  title = {An Adversarial Domain Adaptation Network for Cross-Domain Fine-Grained Recognition},
  author = {Yimu Wang and Ren-Jie Song and Xiu-Shen Wei and Lijun Zhang},
  booktitle = {Winter Conference on Applications of Computer Vision},
  year = {2020}
}</code></pre>
         </div>
         <!-- Global site tag (gtag.js) - Google Analytics -->
         <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-133191784-1"></script>
         <script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            gtag('config', 'UA-133191784-1');
         </script>
      </div>
   </body>
</html>